# Near-Boundary Data

Repository for the paper "Interesting Near-Boundary Data: Inferring Model Ownership for DNNs".

## What does this repository contain?

All the codes used in the paper, including the original model structure, model training and codes for generating initial near-boundary data and training DCgan. The following are specific instructions.

## Dependencies

The repository is written using `python 3.7.11`. To install dependencies run the command:

```
pip install -r requirements.txt
```

## Code framwork

- `model`:Structural codes including original and unrelated models:
  - origin model:ResNet18
  - irrelevant model:VGG11

- `src`: The specific code involved in the method flow: 
  - `cw`:used to generate initial near-boundary data.
  - `DCgan`:for training generative adversarial models.
  - `fine_tune_sourcemodel`: fine-tune the source model with new data generated by DCgan.
  - `model_steal`:mainstream model theft methods, including model fine-tuning, model pruning, knowledge distillation:
    - `fine-tuning`:fine-tune last layer.
    - `model pruning`:different pruning rates of 0.1, 0.3, 0.5.
    - `knowledge distillation`:from RedNet18 to VGG11.
  - `compute_mean_std.py`:calculate the mean and variance of a dataset.
  - `train.py`:train the source model from the original dataset, including data processing and accuracy testing.
